{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVm7NOeWooBT"
      },
      "source": [
        "https://github.com/KevinMusgrave/pytorch-metric-learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMde13VLDjiH"
      },
      "source": [
        "!pip install pytorch-metric-learning > /dev/null\n",
        "!pip install faiss-gpu > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thKgYQF3URYw"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "sns.set()\r\n",
        "\r\n",
        "sns.set_style(\"whitegrid\", {'axes.grid' : False})\r\n",
        "\r\n",
        "# from tqdm.notebook import tqdm\r\n",
        "from tqdm.auto import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TE8tM1jVt5a"
      },
      "source": [
        "# cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBFRCZowUWGt"
      },
      "source": [
        "import torch\r\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-kXTk-bNPzx"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\r\n",
        "\r\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg97KJXdnew6"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zVjbG5ikSLe"
      },
      "source": [
        "normal mnist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo2W99FK8NGQ"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_mLsoBGt4QY"
      },
      "source": [
        "from pytorch_metric_learning import losses, miners, distances, reducers, testers, samplers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFR6JXZY8M_I"
      },
      "source": [
        "transform = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Resize((64, 64)),\r\n",
        "])\r\n",
        "\r\n",
        "trainset = torchvision.datasets.Omniglot(\r\n",
        "    root='./omniglot_data',\r\n",
        "    background=True, # train\r\n",
        "    download=True,\r\n",
        "    transform=transform,\r\n",
        ")\r\n",
        "\r\n",
        "testset = torchvision.datasets.Omniglot(\r\n",
        "    root='./omniglot_data',\r\n",
        "    background=False, # test\r\n",
        "    download=True,\r\n",
        "    transform=transform,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twx-ex7Mmdbm"
      },
      "source": [
        "targets = []\r\n",
        "for _, l in trainset:\r\n",
        "    targets.append(l)\r\n",
        "\r\n",
        "len(targets), len(set(targets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm80PCIl79LE"
      },
      "source": [
        "BATCH_SIZE = 128\r\n",
        "SAMPLES_PER_CLASS = 16 # drawing 16 classes per batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQfIOu14uO9m"
      },
      "source": [
        "sampler = samplers.MPerClassSampler(targets, SAMPLES_PER_CLASS, batch_size=BATCH_SIZE, length_before_new_iter=BATCH_SIZE * 200) # 100 batches per epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W-DuPoHuACu"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(\r\n",
        "    trainset, batch_size=BATCH_SIZE,\r\n",
        "    num_workers=2,\r\n",
        "    sampler=sampler,\r\n",
        ")\r\n",
        "\r\n",
        "testloader = torch.utils.data.DataLoader(\r\n",
        "    testset, batch_size=BATCH_SIZE,\r\n",
        "    num_workers=2,\r\n",
        "    sampler=sampler,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p410_Pb-8MzZ"
      },
      "source": [
        "def imshow(img):\r\n",
        "    npimg = img.numpy()\r\n",
        "\r\n",
        "    npimg = np.transpose(npimg, (1, 2, 0))\r\n",
        "    plt.imshow(npimg)\r\n",
        "\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xjwPULW1rQ5"
      },
      "source": [
        "def imggrid(images, labels, predicted_labels):\r\n",
        "    fig, axs = plt.subplots(figsize=(16, 16))\r\n",
        "    for i in range(len(images[:16])):\r\n",
        "        img = images[i]\r\n",
        "        label = labels[i]\r\n",
        "        predicted_label = predicted_labels[i]\r\n",
        "\r\n",
        "        img = torch.squeeze(np.transpose(img, (1, 2, 0)))\r\n",
        "        ax = plt.subplot(4, 4, i+1)\r\n",
        "        ax.imshow(img, cmap='gray')\r\n",
        "\r\n",
        "        color = 'black' if label == predicted_label else 'red'\r\n",
        "        ax.set_title(f'True: {label}. Predicted: {predicted_label}', {'color': color})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d3Qdc-J3DSY"
      },
      "source": [
        "dataiter = iter(trainloader)\r\n",
        "images, labels = dataiter.next()\r\n",
        "\r\n",
        "imggrid(images, labels.numpy(), labels.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhXjo4Rjl-JV"
      },
      "source": [
        "# Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUkvqBZgomf8"
      },
      "source": [
        "# 1x64x64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsXGNkxe7V7N"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OMmiCF5asZm"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "    def __init__(self, channels_img, features_d):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        \r\n",
        "        self.layer = nn.Sequential(\r\n",
        "            # N * channels_img * 64 * 64\r\n",
        "            nn.Conv2d(\r\n",
        "                channels_img,\r\n",
        "                features_d,\r\n",
        "                kernel_size=4,\r\n",
        "                stride=2,\r\n",
        "                padding=1,\r\n",
        "            ),\r\n",
        "            # features_d * 32 * 32\r\n",
        "            nn.LeakyReLU(0.2),\r\n",
        "            self._block(features_d, features_d*2, 4, 2, 1), # 16 * 16\r\n",
        "            self._block(features_d*2, features_d*4, 4, 2, 1), # 8 * 8\r\n",
        "            self._block(features_d*4, features_d*8, 4, 2, 1), # 4 * 4 * features_d*8\r\n",
        "            nn.Flatten(),\r\n",
        "            nn.Linear(4*4*features_d*8, features_d*8),\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.layer(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\r\n",
        "        return nn.Sequential(\r\n",
        "            nn.Conv2d(\r\n",
        "                in_channels,\r\n",
        "                out_channels,\r\n",
        "                kernel_size,\r\n",
        "                stride,\r\n",
        "                padding,\r\n",
        "                bias=False,\r\n",
        "            ),\r\n",
        "            nn.BatchNorm2d(out_channels),\r\n",
        "            nn.LeakyReLU(0.2)\r\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtco0bnIonc0"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEAMWMFGxXwR"
      },
      "source": [
        "FEATURES_DIM = 8\r\n",
        "LR = 1e-3\r\n",
        "NUM_EPOCHS = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZBeoMARzDpJ"
      },
      "source": [
        "model = Net(1, FEATURES_DIM).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YuKXKv_zEX3"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=LR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzpMLdIMyUWp"
      },
      "source": [
        "distance = distances.CosineSimilarity()\r\n",
        "reducer = reducers.ThresholdReducer(low = 0)\r\n",
        "loss_func = losses.TripletMarginLoss(margin = 0.2, distance = distance, reducer = reducer)\r\n",
        "mining_func = miners.TripletMarginMiner(margin = 0.2, distance = distance, type_of_triplets = \"semihard\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDLxFpONoopm"
      },
      "source": [
        "model.train()\r\n",
        "\r\n",
        "for epoch in tqdm(range(NUM_EPOCHS)):\r\n",
        "    for batch_idx, (data, labels) in enumerate(trainloader):\r\n",
        "        data, labels = data.to(device), labels.to(device)\r\n",
        "\r\n",
        "        embeddings = model(data)\r\n",
        "        indices_tuple = mining_func(embeddings, labels)\r\n",
        "        loss = loss_func(embeddings, labels, indices_tuple)\r\n",
        "\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        # if epoch % 5 == 0:\r\n",
        "            # print(\"Epoch {} Iteration {}: Loss = {}, Number of mined triplets = {}\".format(epoch, batch_idx, loss, mining_func.num_triplets))\r\n",
        "    print(\"Epoch {} Loss = {}\".format(epoch, loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR_DyzWGLY44"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KwbvKTtJ3DK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_x9Nj8R2Sto"
      },
      "source": [
        "model.eval();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfmcw47m2LNb"
      },
      "source": [
        "e = model(images.to(device)).to('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWdKyu4h2OVp"
      },
      "source": [
        "((e[0]- e[1])**2).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzvY_YcT2QiR"
      },
      "source": [
        "((e[0]- e[31])**2).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkqGwa1J2dVL"
      },
      "source": [
        "((e[30]- e[31])**2).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNxlq0JR2fna"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}