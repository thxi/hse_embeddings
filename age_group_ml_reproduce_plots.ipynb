{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finnish-harris",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Arch\" data-toc-modified-id=\"Arch-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Arch</a></span></li><li><span><a href=\"#Embedding-dim\" data-toc-modified-id=\"Embedding-dim-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Embedding dim</a></span></li><li><span><a href=\"#Cat-embedding-dim\" data-toc-modified-id=\"Cat-embedding-dim-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Cat embedding dim</a></span></li><li><span><a href=\"#Num-observations\" data-toc-modified-id=\"Num-observations-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Num observations</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "inner-canada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:36:12.634204Z",
     "start_time": "2021-05-19T11:36:11.762377Z"
    },
    "id": "thKgYQF3URYw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sublime-strap",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:36:12.648694Z",
     "start_time": "2021-05-19T11:36:12.635893Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "polar-married",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:36:13.412189Z",
     "start_time": "2021-05-19T11:36:12.650168Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBFRCZowUWGt",
    "outputId": "09cfb931-6126-4fcf-f0b6-d6abfa0d4ba5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "infectious-providence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:36:13.426562Z",
     "start_time": "2021-05-19T11:36:13.413382Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-kXTk-bNPzx",
    "outputId": "7a991cca-3b7a-4ec3-9fa8-ee0b5fce2537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "peaceful-chaos",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:36:13.644120Z",
     "start_time": "2021-05-19T11:36:13.427805Z"
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import losses, miners, distances, reducers, samplers\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "romantic-brook",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:36:13.666353Z",
     "start_time": "2021-05-19T11:36:13.645417Z"
    }
   },
   "outputs": [],
   "source": [
    "from code.dataloader import AgeGroupMLDataset, AgeGroupClfDataset\n",
    "from code.encoder_gru import Encoder\n",
    "from code.decoder import Decoder\n",
    "from code.classifier import Classifier\n",
    "from code.utils import train_ml_model, train_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "upset-raising",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:36:13.686779Z",
     "start_time": "2021-05-19T11:36:13.669554Z"
    },
    "id": "pm80PCIl79LE"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 # BATCH_SIZE unique persons\n",
    "NUM_OF_SUBSEQUENCES = 5\n",
    "SUBSEQUENCE_LENGTH = 90\n",
    "\n",
    "EMBEDDING_DIM = 256\n",
    "LR = 0.002\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "cat_vocab_sizes = [204]\n",
    "cat_embedding_dim = 102\n",
    "num_input_dim = 4\n",
    "NUM_OBS = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "identified-movement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:36:13.705755Z",
     "start_time": "2021-05-19T11:36:13.688735Z"
    }
   },
   "outputs": [],
   "source": [
    "arches = (\n",
    "    ('GRU', nn.GRU(\n",
    "                num_input_dim + cat_embedding_dim,\n",
    "                EMBEDDING_DIM,\n",
    "                batch_first=False),\n",
    "    ),\n",
    "    ('LSTM', nn.LSTM(\n",
    "                num_input_dim + cat_embedding_dim,\n",
    "                EMBEDDING_DIM,\n",
    "                batch_first=False),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "material-dimension",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:36:38.528344Z",
     "start_time": "2021-05-19T11:36:13.707092Z"
    },
    "id": "GYYj4IyZdrtg"
   },
   "outputs": [],
   "source": [
    "dataset = AgeGroupMLDataset(num_observations=NUM_OBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "seventh-think",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:36:38.673224Z",
     "start_time": "2021-05-19T11:36:38.535073Z"
    },
    "id": "EY6GM_RjsCWg"
   },
   "outputs": [],
   "source": [
    "dataset.load_client_to_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "registered-alpha",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:37:00.153490Z",
     "start_time": "2021-05-19T11:36:38.674361Z"
    },
    "id": "ZZyL5MiF-Ufm"
   },
   "outputs": [],
   "source": [
    "clfdataset = AgeGroupClfDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bridal-livestock",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:37:00.202893Z",
     "start_time": "2021-05-19T11:37:00.154618Z"
    },
    "id": "nW8khMXN-STb"
   },
   "outputs": [],
   "source": [
    "clfdataset.load_client_to_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "linear-trinidad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:37:00.220044Z",
     "start_time": "2021-05-19T11:37:00.203888Z"
    },
    "id": "WxzkX-VZ3zJu"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "peaceful-diameter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T11:37:00.243481Z",
     "start_time": "2021-05-19T11:37:00.221151Z"
    },
    "id": "2W-DuPoHuACu"
   },
   "outputs": [],
   "source": [
    "targets = dataset.targets\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=BATCH_SIZE,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "targets = clfdataset.targets\n",
    "\n",
    "train_idx, test_idx= train_test_split(\n",
    "    np.arange(len(targets)),\n",
    "    test_size=0.3,\n",
    "    shuffle=True,\n",
    "    stratify=targets,\n",
    "    random_state=228\n",
    ")\n",
    "\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    clfdataset, batch_size=BATCH_SIZE,\n",
    "    sampler=train_sampler)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    clfdataset, batch_size=BATCH_SIZE,\n",
    "    sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-folder",
   "metadata": {},
   "source": [
    "## Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-legend",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T10:15:23.464980Z",
     "start_time": "2021-05-06T09:55:54.597891Z"
    }
   },
   "outputs": [],
   "source": [
    "for (arch, cell) in tqdm(arches):\n",
    "    print(arch)\n",
    "    LR = 0.002\n",
    "    \n",
    "    # train decoder\n",
    "    \n",
    "    encoder = Encoder(\n",
    "        numerical_input_dim=num_input_dim,\n",
    "        cat_vocab_sizes=cat_vocab_sizes,\n",
    "        cat_embedding_dim=cat_embedding_dim,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "    )\n",
    "    encoder.sequence_encoder = cell\n",
    "    encoder.to(device);\n",
    "    optimizer = optim.Adam(encoder.parameters(), lr=LR)\n",
    "    \n",
    "    distance = distances.CosineSimilarity()\n",
    "    reducer = reducers.ThresholdReducer(low = 0) # basically, returns average\n",
    "    loss_func = losses.TripletMarginLoss(margin = 0.4, distance = distance, reducer = reducer)\n",
    "    mining_func = miners.TripletMarginMiner(margin = 0.4, distance = distance, type_of_triplets = \"semihard\")\n",
    "    \n",
    "    train_losses = train_ml_model(\n",
    "        encoder, NUM_EPOCHS, dataloader, NUM_OF_SUBSEQUENCES,\n",
    "        mining_func, loss_func, optimizer)\n",
    "    fig, axs = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.xlabel('iter')\n",
    "    plt.ylabel('loss');\n",
    "    plt.savefig(f'plots/ML_{arch}_{EMBEDDING_DIM}_{NUM_OBS}_{NUM_EPOCHS}.png')\n",
    "    \n",
    "    SCHEDULER_EPOCHS = 2\n",
    "    LR = 0.002\n",
    "    \n",
    "    # train classifier decoder\n",
    "    \n",
    "    classifier = Classifier(\n",
    "        numerical_input_dim=num_input_dim,\n",
    "        cat_vocab_sizes=cat_vocab_sizes,\n",
    "        cat_embedding_dim=cat_embedding_dim,\n",
    "        embedding_dim=EMBEDDING_DIM\n",
    "    )\n",
    "    classifier.encoder = encoder\n",
    "    classifier.freeze_encoder()\n",
    "    classifier.to(device);\n",
    "    \n",
    "    optimizer = optim.Adam(classifier.decoder.parameters(), lr=LR)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        patience=SCHEDULER_EPOCHS,\n",
    "    )\n",
    "    \n",
    "    train_losses, train_accuracy, val_losses, val_accuracy = train_classifier(\n",
    "        classifier, NUM_EPOCHS, trainloader, testloader,\n",
    "        optimizer, criterion, scheduler,\n",
    "        enable_train_mode = lambda: classifier.decoder.train(),\n",
    "        enable_test_mode = lambda: classifier.decoder.eval(),\n",
    "    )\n",
    "    \n",
    "    fig, axs = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.plot(val_losses, label='validation')\n",
    "    plt.xlabel('iter')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.xlabel('iter')\n",
    "    plt.ylabel('accuracy');\n",
    "    plt.plot(train_accuracy, label='train')\n",
    "    plt.plot(val_accuracy, label='validation')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'plots/clfdec_{arch}_{EMBEDDING_DIM}_{NUM_OBS}_{NUM_EPOCHS}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-sailing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:33:05.181787Z",
     "start_time": "2021-05-11T11:33:05.108153Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-christian",
   "metadata": {},
   "source": [
    "## Embedding dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-subscriber",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T14:48:48.771049Z",
     "start_time": "2021-05-06T12:04:36.952962Z"
    }
   },
   "outputs": [],
   "source": [
    "arch = 'GRU'\n",
    "\n",
    "dims = [32, 64, 128, 256, 512, 1024]\n",
    "accs = []\n",
    "\n",
    "for EMBEDDING_DIM in tqdm(dims):\n",
    "    print(EMBEDDING_DIM)\n",
    "    LR = 0.002\n",
    "    \n",
    "    # train decoder\n",
    "    \n",
    "    encoder = Encoder(\n",
    "        numerical_input_dim=num_input_dim,\n",
    "        cat_vocab_sizes=cat_vocab_sizes,\n",
    "        cat_embedding_dim=cat_embedding_dim,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "    )\n",
    "    encoder.to(device);\n",
    "    encoder.train()\n",
    "    optimizer = optim.Adam(encoder.parameters(), lr=LR)\n",
    "    \n",
    "    distance = distances.CosineSimilarity()\n",
    "    reducer = reducers.ThresholdReducer(low = 0) # basically, returns average\n",
    "    loss_func = losses.TripletMarginLoss(margin = 0.4, distance = distance, reducer = reducer)\n",
    "    mining_func = miners.TripletMarginMiner(margin = 0.4, distance = distance, type_of_triplets = \"semihard\")\n",
    "    \n",
    "    train_losses = train_ml_model(\n",
    "        encoder, NUM_EPOCHS, dataloader, NUM_OF_SUBSEQUENCES,\n",
    "        mining_func, loss_func, optimizer)\n",
    "    fig, axs = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.xlabel('iter')\n",
    "    plt.ylabel('loss');\n",
    "    plt.savefig(f'plots/ML_{arch}_{EMBEDDING_DIM}_{NUM_OBS}_{NUM_EPOCHS}.png')\n",
    "    \n",
    "    SCHEDULER_EPOCHS = 2\n",
    "    LR = 0.002\n",
    "    \n",
    "    # train classifier decoder\n",
    "    \n",
    "    classifier = Classifier(\n",
    "        numerical_input_dim=num_input_dim,\n",
    "        cat_vocab_sizes=cat_vocab_sizes,\n",
    "        cat_embedding_dim=cat_embedding_dim,\n",
    "        embedding_dim=EMBEDDING_DIM\n",
    "    )\n",
    "    classifier.encoder = encoder\n",
    "    classifier.freeze_encoder()\n",
    "    classifier.to(device);\n",
    "    \n",
    "    optimizer = optim.Adam(classifier.decoder.parameters(), lr=LR)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        patience=SCHEDULER_EPOCHS,\n",
    "    )\n",
    "    \n",
    "    train_losses, train_accuracy, val_losses, val_accuracy = train_classifier(\n",
    "        classifier, NUM_EPOCHS, trainloader, testloader,\n",
    "        optimizer, criterion, scheduler,\n",
    "        enable_train_mode = lambda: classifier.decoder.train(),\n",
    "        enable_test_mode = lambda: classifier.decoder.eval(),\n",
    "    )\n",
    "    \n",
    "    fig, axs = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.plot(val_losses, label='validation')\n",
    "    plt.xlabel('iter')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.xlabel('iter')\n",
    "    plt.ylabel('accuracy');\n",
    "    plt.plot(train_accuracy, label='train')\n",
    "    plt.plot(val_accuracy, label='validation')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'plots/clfdec_{arch}_{EMBEDDING_DIM}_{NUM_OBS}_{NUM_EPOCHS}.png')\n",
    "    \n",
    "    accs.append(val_accuracy[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dims, accs)\n",
    "plt.xlabel('Embedding dimension')\n",
    "plt.ylabel('accuracy');\n",
    "plt.savefig(f'plots/clfdec_{arch}_embedding_to_acc_{NUM_OBS}_{NUM_EPOCHS}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-mediterranean",
   "metadata": {},
   "source": [
    "## Cat embedding dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-classification",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-19T11:37:32.094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23364b88e534dc9b717cffe0c2b8ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8996a57c5346ee811b77279126c5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arch = 'GRU'\n",
    "\n",
    "EMBEDDING_DIM = 256\n",
    "NUM_EPOCHS=20\n",
    "dims = [20, 40, 60, 80, 100]\n",
    "accs = []\n",
    "\n",
    "for cat_embedding_dim in tqdm(dims):\n",
    "    print(cat_embedding_dim)\n",
    "    LR = 0.002\n",
    "    \n",
    "    # train decoder\n",
    "    \n",
    "    encoder = Encoder(\n",
    "        numerical_input_dim=num_input_dim,\n",
    "        cat_vocab_sizes=cat_vocab_sizes,\n",
    "        cat_embedding_dim=cat_embedding_dim,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "    )\n",
    "    encoder.to(device);\n",
    "    encoder.train()\n",
    "    optimizer = optim.Adam(encoder.parameters(), lr=LR)\n",
    "    \n",
    "    distance = distances.CosineSimilarity()\n",
    "    reducer = reducers.ThresholdReducer(low = 0) # basically, returns average\n",
    "    loss_func = losses.TripletMarginLoss(margin = 0.4, distance = distance, reducer = reducer)\n",
    "    mining_func = miners.TripletMarginMiner(margin = 0.4, distance = distance, type_of_triplets = \"semihard\")\n",
    "    \n",
    "    train_losses = train_ml_model(\n",
    "        encoder, NUM_EPOCHS, dataloader, NUM_OF_SUBSEQUENCES,\n",
    "        mining_func, loss_func, optimizer)\n",
    "    fig, axs = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.xlabel('iter')\n",
    "    plt.ylabel('loss');\n",
    "    plt.title(f'{cat_embedding_dim}')\n",
    "    \n",
    "    SCHEDULER_EPOCHS = 2\n",
    "    LR = 0.002\n",
    "    \n",
    "    # train classifier decoder\n",
    "    \n",
    "    classifier = Classifier(\n",
    "        numerical_input_dim=num_input_dim,\n",
    "        cat_vocab_sizes=cat_vocab_sizes,\n",
    "        cat_embedding_dim=cat_embedding_dim,\n",
    "        embedding_dim=EMBEDDING_DIM\n",
    "    )\n",
    "    classifier.encoder = encoder\n",
    "    classifier.freeze_encoder()\n",
    "    classifier.to(device);\n",
    "    \n",
    "    optimizer = optim.Adam(classifier.decoder.parameters(), lr=LR)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        patience=SCHEDULER_EPOCHS,\n",
    "    )\n",
    "    \n",
    "    train_losses, train_accuracy, val_losses, val_accuracy = train_classifier(\n",
    "        classifier, NUM_EPOCHS, trainloader, testloader,\n",
    "        optimizer, criterion, scheduler,\n",
    "        enable_train_mode = lambda: classifier.decoder.train(),\n",
    "        enable_test_mode = lambda: classifier.decoder.eval(),\n",
    "    )\n",
    "    \n",
    "    fig, axs = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.plot(val_losses, label='validation')\n",
    "    plt.xlabel('iter')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.xlabel('iter')\n",
    "    plt.ylabel('accuracy');\n",
    "    plt.plot(train_accuracy, label='train')\n",
    "    plt.plot(val_accuracy, label='validation')\n",
    "    plt.legend()\n",
    "    \n",
    "    accs.append(val_accuracy[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dims, accs)\n",
    "plt.xlabel('categorical embedding dimension')\n",
    "plt.ylabel('accuracy');\n",
    "plt.savefig(f'plots/clfdec_{arch}_cat_embedding_to_acc_{NUM_OBS}_{NUM_EPOCHS}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-tsunami",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-lightweight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-windows",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-genealogy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-antarctica",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T13:59:35.054888Z",
     "start_time": "2021-05-11T13:59:01.663156Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = AgeGroupMLDataset()\n",
    "dataset.load_client_to_indices()\n",
    "clfdataset = AgeGroupClfDataset()\n",
    "clfdataset.load_client_to_indices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-wesley",
   "metadata": {},
   "source": [
    "## Num observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-television",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T15:04:07.267127Z",
     "start_time": "2021-05-11T14:03:18.558270Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arch = 'GRU'\n",
    "\n",
    "EMBEDDING_DIM = 256\n",
    "nums_epochs = [300, 200, 200, 100, 100, 75, 50]\n",
    "nums_obs = [300, 600, 1300, 2700, 5400, 10800, 21600]\n",
    "nums_epochs = nums_epochs[::-1]\n",
    "nums_obs = nums_obs[::-1]\n",
    "accs = []\n",
    "\n",
    "for NUM_OBS, NUM_EPOCHS in tqdm(zip(nums_obs, nums_epochs)):\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(NUM_OBS, NUM_EPOCHS)\n",
    "    \n",
    "    dataset.targets = dataset.targets[:NUM_OBS]\n",
    "    clfdataset.targets = clfdataset.targets[:NUM_OBS]\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=BATCH_SIZE,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    train_idx, test_idx= train_test_split(\n",
    "        np.arange(len(clfdataset.targets)),\n",
    "        test_size=0.3,\n",
    "        shuffle=True,\n",
    "        stratify=clfdataset.targets,\n",
    "        random_state=228\n",
    "    )\n",
    "\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        clfdataset, batch_size=BATCH_SIZE,\n",
    "        sampler=train_sampler)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        clfdataset, batch_size=BATCH_SIZE,\n",
    "        sampler=test_sampler)\n",
    "    \n",
    "    LR = 0.002\n",
    "    \n",
    "    # train decoder\n",
    "    \n",
    "    encoder = Encoder(\n",
    "        numerical_input_dim=num_input_dim,\n",
    "        cat_vocab_sizes=cat_vocab_sizes,\n",
    "        cat_embedding_dim=cat_embedding_dim,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "    )\n",
    "    encoder.to(device);\n",
    "    encoder.train()\n",
    "    optimizer = optim.Adam(encoder.parameters(), lr=LR)\n",
    "    \n",
    "    distance = distances.CosineSimilarity()\n",
    "    reducer = reducers.ThresholdReducer(low = 0) # basically, returns average\n",
    "    loss_func = losses.TripletMarginLoss(margin = 0.4, distance = distance, reducer = reducer)\n",
    "    mining_func = miners.TripletMarginMiner(margin = 0.4, distance = distance, type_of_triplets = \"semihard\")\n",
    "    \n",
    "    train_losses = train_ml_model(\n",
    "        encoder, NUM_EPOCHS, dataloader, NUM_OF_SUBSEQUENCES,\n",
    "        mining_func, loss_func, optimizer)\n",
    "    fig, axs = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.xlabel('iter')\n",
    "    plt.ylabel('loss');\n",
    "    plt.savefig(f'plots/ML_{arch}_{EMBEDDING_DIM}_{NUM_OBS}_{NUM_EPOCHS}.png')\n",
    "    \n",
    "    SCHEDULER_EPOCHS = 2\n",
    "    LR = 0.002\n",
    "    \n",
    "    # train classifier decoder\n",
    "    \n",
    "    classifier = Classifier(\n",
    "        numerical_input_dim=num_input_dim,\n",
    "        cat_vocab_sizes=cat_vocab_sizes,\n",
    "        cat_embedding_dim=cat_embedding_dim,\n",
    "        embedding_dim=EMBEDDING_DIM\n",
    "    )\n",
    "    classifier.encoder = encoder\n",
    "    classifier.freeze_encoder()\n",
    "    classifier.to(device);\n",
    "    \n",
    "    optimizer = optim.Adam(classifier.decoder.parameters(), lr=LR)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        patience=SCHEDULER_EPOCHS,\n",
    "    )\n",
    "    \n",
    "    train_losses, train_accuracy, val_losses, val_accuracy = train_classifier(\n",
    "        classifier, NUM_EPOCHS, trainloader, testloader,\n",
    "        optimizer, criterion, scheduler,\n",
    "        enable_train_mode = lambda: classifier.decoder.train(),\n",
    "        enable_test_mode = lambda: classifier.decoder.eval(),\n",
    "    )\n",
    "    \n",
    "    fig, axs = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.plot(val_losses, label='validation')\n",
    "    plt.xlabel('iter')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.xlabel('iter')\n",
    "    plt.ylabel('accuracy');\n",
    "    plt.plot(train_accuracy, label='train')\n",
    "    plt.plot(val_accuracy, label='validation')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'plots/clfdec_{arch}_{EMBEDDING_DIM}_{NUM_OBS}_{NUM_EPOCHS}.png')\n",
    "    \n",
    "    accs.append(val_accuracy[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-debate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-blowing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-wireless",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-bhutan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-champagne",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:45:18.148310Z",
     "start_time": "2021-05-11T10:45:18.117065Z"
    }
   },
   "outputs": [],
   "source": [
    "dims = [32, 64, 128, 256, 512, 1024, 2048]\n",
    "\n",
    "accs = [0.5453333258628845,\n",
    " 0.558555543422699,\n",
    " 0.558222234249115,\n",
    " 0.5707777738571167,\n",
    " 0.5681111216545105,\n",
    " 0.5681111216545105,\n",
    " 0.45866668224334717]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-investor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T14:52:24.338194Z",
     "start_time": "2021-05-06T14:52:24.114519Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(dims, accs)\n",
    "plt.xlabel('Embedding dimension')\n",
    "plt.xscale('log', base=2)\n",
    "plt.xticks(dims)\n",
    "plt.ylabel('accuracy');\n",
    "plt.savefig(f'plots/clfdec_{arch}_embedding_to_acc_{NUM_OBS}_{NUM_EPOCHS}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-knitting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-parks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-willow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-operation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:46:09.792839Z",
     "start_time": "2021-05-11T10:46:09.769132Z"
    }
   },
   "outputs": [],
   "source": [
    "arch = 'GRU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-albert",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:47:48.105387Z",
     "start_time": "2021-05-11T10:47:48.073474Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-mainland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T10:48:08.904000Z",
     "start_time": "2021-05-11T10:48:08.571893Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.lineplot(x=dims, y=accs)\n",
    "plt.plot(dims, accs)\n",
    "plt.scatter(dims, accs)\n",
    "plt.xlabel('Embedding size')\n",
    "plt.xscale('log', base=2)\n",
    "plt.xticks(dims)\n",
    "plt.ylabel('accuracy');\n",
    "plt.savefig(f'plots/clfdec_{arch}_embedding_to_acc_{NUM_OBS}_{NUM_EPOCHS}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-resort",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-register",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-attitude",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-hebrew",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-league",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_train = torch.zeros((1, EMBEDDING_DIM))[1:].to(device)\n",
    "\n",
    "for (sequences, labels) in trainloader:\n",
    "    with torch.no_grad():\n",
    "        n, c = sequences[0], sequences[1]\n",
    "        n = n.to(device)\n",
    "        c = c.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        embedding = encoder(n, c)\n",
    "        \n",
    "        embeddings_train = torch.cat((embeddings_train, embedding))\n",
    "        \n",
    "embeddings_test = torch.zeros((1, EMBEDDING_DIM))[1:].to(device)\n",
    "\n",
    "for (sequences, labels) in testloader:\n",
    "    with torch.no_grad():\n",
    "        n, c = sequences[0], sequences[1]\n",
    "        n = n.to(device)\n",
    "        c = c.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        embedding = encoder(n, c)\n",
    "        \n",
    "        embeddings = torch.cat((embeddings_test, embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_train = embeddings_train.to('cpu')\n",
    "embeddings_test = embeddings_test.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = embeddings_train\n",
    "X_test = embeddings_test\n",
    "y_train = targets[train_idx]\n",
    "y_test = targets[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-childhood",
   "metadata": {
    "id": "L5jmrerQ9qRg"
   },
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-montgomery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-latter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-orbit",
   "metadata": {
    "id": "Ca5R3rL7Kxem"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from catboost import cv\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-regression",
   "metadata": {
    "id": "D38VYwhXKq_P"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=228, stratify=y)\n",
    "\n",
    "train_pool = Pool(X_train, y_train)\n",
    "test_pool = Pool(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-vietnamese",
   "metadata": {
    "id": "YV_oTIQKNsuq"
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    depth=3,\n",
    "    learning_rate=0.5,\n",
    "    verbose=True,\n",
    "    eval_metric='Accuracy',\n",
    "    auto_class_weights='Balanced',\n",
    "    random_state=228,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-wings",
   "metadata": {
    "id": "Fc3FHXYyK8yh"
   },
   "outputs": [],
   "source": [
    "model.fit(train_pool, eval_set=test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-binary",
   "metadata": {
    "id": "63NEh9tOkAkp"
   },
   "outputs": [],
   "source": [
    "train_acc = model.evals_result_['learn']['Accuracy']\n",
    "valid_acc = model.evals_result_['validation']['Accuracy']\n",
    "\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(valid_acc, label='valid')\n",
    "plt.xlabel('iter')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-forge",
   "metadata": {
    "id": "dLfhuxFdkAiV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-stomach",
   "metadata": {
    "id": "Gq_9OK9INyco"
   },
   "outputs": [],
   "source": [
    "sum(np.squeeze(model.predict(X_test)) == y_test) / len(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "191px",
    "width": "260px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
